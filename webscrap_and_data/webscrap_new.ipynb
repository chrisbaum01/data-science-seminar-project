{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d72b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get product id & product url from downloaded ishare ETF html file\n",
    "# this is for downloading up-to-date holdings file from ishare\n",
    "website_header = \"https://www.ishares.com\"\n",
    "\n",
    "html = open(\"product_id_ishare.html\", encoding=\"utf-8\").read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "rows = soup.select(\"tr:has(td.links a[href*='/produkte/'])\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for row in rows:\n",
    "    links = row.select(\"td.links a\")\n",
    "\n",
    "    if len(links) >= 2:\n",
    "        product_url = links[0].get(\"href\")\n",
    "\n",
    "        ids = [re.search(r\"/produkte/(\\d+)/\", a[\"href\"]).group(1) for a in links[:2]]\n",
    "\n",
    "        id1, id2 = ids\n",
    "        ticker = links[0].get_text(strip=True)\n",
    "        fund_name = links[1].get_text(strip=True)\n",
    "        records.append(\n",
    "            {\n",
    "                \"product_id\": id2,\n",
    "                'product_url':website_header + product_url,\n",
    "                \"ticker\": ticker,\n",
    "                \"fund_name\": fund_name,\n",
    "                \"flag\": id1 == id2,\n",
    "            }\n",
    "        )\n",
    "records_df = pd.DataFrame(records)\n",
    "records_df['ticker']=records_df['ticker'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load selected ETF dataframe\n",
    "ETF_file = pd.read_excel(\"iShares-Germany_filtered_ETF_descending.xlsx\")\n",
    "mask_etf = ETF_file[\"Fondstyp\"] == \"ETF\"\n",
    "mask_asset_class = ETF_file[\"Anlageklasse\"] == \"Aktien\"\n",
    "filtered_etf = (\n",
    "    ETF_file[mask_etf & mask_asset_class]\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"Fondsvermögen\", ascending=False)\n",
    ")\n",
    "# select top 120\n",
    "filtered_etf=filtered_etf.head(120)\n",
    "filtered_etf['Ticker'] = filtered_etf['Ticker'].apply(lambda x: x.strip())\n",
    "\n",
    "tickers = filtered_etf['Ticker'].tolist()\n",
    "tickers = [ticker.strip() for ticker in tickers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083bc3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare ticker names for yfinance price download\n",
    "suffixes = [\".DE\", \".L\", \".SW\", \".MI\", \".PA\", \".AS\"]\n",
    "\n",
    "def find_valid_ticker(base):\n",
    "    for s in suffixes:\n",
    "        t = base + s\n",
    "        data = yf.download(t, period=\"5d\", progress=False)\n",
    "        if not data.empty:\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "valid_map = {}\n",
    "invalid = []\n",
    "\n",
    "for t in tickers:\n",
    "    if t.__contains__('.'):\n",
    "        real = t\n",
    "    else:\n",
    "        real = find_valid_ticker(t)\n",
    "\n",
    "    if real:\n",
    "        valid_map[t] = real\n",
    "    else:\n",
    "        invalid.append(t)\n",
    "\n",
    "print(valid_map)\n",
    "print(\"still invalid:\", invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download prices from yfinance\n",
    "valid_tickers = list(valid_map.values())\n",
    "data = yf.download(valid_tickers, period=\"3y\")\n",
    "\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    adj_close = data[\"Close\"]\n",
    "else:\n",
    "    adj_close = data[[\"Close\"]]  # For single ticker cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prices\n",
    "adj_close.reset_index().melt(id_vars=['Date']).to_csv('prices.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5114237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if all selected tickers are available in the downloaded html ishare file\n",
    "manual_list = []\n",
    "for tick in tickers:\n",
    "    if tick not in records_df['ticker'].tolist():\n",
    "        print(f'???{tick} not found')\n",
    "        manual_list.append(tick)\n",
    "\n",
    "print(manual_list)\n",
    "print(len(manual_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d99300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records_df['duplicated'] = records_df['ticker'].duplicated()\n",
    "# TODO  handle the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelevant tickers\n",
    "records_df = records_df[records_df['ticker'].isin(filtered_etf['Ticker'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4ff1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records_df) #TODO: handle the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5066ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_ishares_download_link(product_url, fund_name):\n",
    "    \"\"\"\n",
    "    generate link for downloading holdings info for a specified ETF\n",
    "    \"\"\"\n",
    "\n",
    "    magic_string = \"1535604580385\"\n",
    "    base_url = f\"{product_url}/{magic_string}.ajax\"\n",
    "    file_name = '-'.join([x.strip().upper() for x in fund_name.split()])\n",
    "    params = f\"?fileType=xls&fileName={file_name}_fund&dataType=fund\"\n",
    "    \n",
    "    return base_url + params\n",
    "\n",
    "xls_file_url_list = []\n",
    "for row in records:\n",
    "    final_href = generate_ishares_download_link(row['product_url'], row['fund_name'])\n",
    "    # print(f\"Generated URL: {final_href}\")\n",
    "    xls_file_url_list.append({'download_url': final_href,'product_id':row['product_id']})\n",
    "# extend records_df by product download url\n",
    "records_df = pd.merge(pd.DataFrame(xls_file_url_list),records_df,how='right',on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f50caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_etf_data(df, ticker):\n",
    "    \"\"\"\n",
    "    input: df, Ticker, TER\n",
    "    output: (industry_df, location_df)\n",
    "    \"\"\"\n",
    "    # 1. convert: iShares XML 'Gewichtung (%)' e.g. 1.66856% --> /100\n",
    "    df['Weight_Decimal'] = pd.to_numeric(df['Gewichtung (%)'], errors='coerce') / 100\n",
    "    \n",
    "    # 2. industry\n",
    "    industry_agg = df.groupby('Sektor')['Weight_Decimal'].sum().reset_index()\n",
    "    industry_agg.columns = ['Sector', 'Weight']\n",
    "    industry_agg['Ticker'] = ticker\n",
    "    \n",
    "    # 3. country\n",
    "    location_agg = df.groupby('Standort')['Weight_Decimal'].sum().reset_index()\n",
    "    location_agg.columns = ['Location', 'Weight']\n",
    "    location_agg['Ticker'] = ticker\n",
    "    \n",
    "    return industry_agg, location_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def parse_holdings_xls(xml_path):\n",
    "    # ===== 1. read in file =====\n",
    "    with open(xml_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # ===== 2. XML =====\n",
    "    xml_start = content.find(\"<?xml\")\n",
    "    if xml_start == -1:\n",
    "        raise ValueError(\"XML not found in file\")\n",
    "\n",
    "    clean_xml = content[xml_start:]\n",
    "\n",
    "    # ===== 3. decode XML =====\n",
    "    root = ET.fromstring(clean_xml)\n",
    "\n",
    "    ns = {\"ss\": \"urn:schemas-microsoft-com:office:spreadsheet\"}\n",
    "\n",
    "    table = root.find(\".//ss:Worksheet/ss:Table\", ns)\n",
    "    rows = table.findall(\"ss:Row\", ns)\n",
    "\n",
    "    header = None\n",
    "    data = []\n",
    "    start = False\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.findall(\"ss:Cell\", ns)\n",
    "        values = []\n",
    "\n",
    "        for cell in cells:\n",
    "            d = cell.find(\"ss:Data\", ns)\n",
    "            values.append(d.text if d is not None else None)\n",
    "\n",
    "        # get table header\n",
    "        if values and \"Emittententicker\" in values:\n",
    "            header = values\n",
    "            start = True\n",
    "            continue\n",
    "\n",
    "        if start and any(v not in (None, \"\") for v in values):\n",
    "            data.append(values)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "    # print(df.head())\n",
    "    print(f\"\\nsuccessfully extracted {len(df)} rows\")\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77f623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "成功提取 310 行\n",
      "✅ IQQ0 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 42\n",
      "status code: 403 for ticker IUSC\n",
      "status code: 403 for ticker DAXEX\n",
      "\n",
      "成功提取 137 行\n",
      "✅ EUNY 聚合完成\n",
      "\n",
      "成功提取 134 行\n",
      "✅ IUSK 聚合完成\n",
      "\n",
      "成功提取 636 行\n",
      "✅ IUSL 聚合完成\n",
      "\n",
      "成功提取 68 行\n",
      "✅ EXI2 聚合完成\n",
      "\n",
      "成功提取 304 行\n",
      "✅ EXSI 聚合完成\n",
      "\n",
      "成功提取 55 行\n",
      "✅ EUN2 聚合完成\n",
      "\n",
      "成功提取 55 行\n",
      "✅ EXW1 聚合完成\n",
      "\n",
      "成功提取 33 行\n",
      "✅ EXX1 聚合完成\n",
      "\n",
      "成功提取 35 行\n",
      "✅ IQQA 聚合完成\n",
      "\n",
      "成功提取 107 行\n",
      "✅ IUSZ 聚合完成\n",
      "\n",
      "成功提取 57 行\n",
      "✅ IQQC 聚合完成\n",
      "\n",
      "成功提取 57 行\n",
      "✅ IQQD 聚合完成\n",
      "\n",
      "成功提取 300 行\n",
      "✅ IQQI 聚合完成\n",
      "status code: 403 for ticker EXS3\n",
      "\n",
      "成功提取 480 行\n",
      "✅ IQQF 聚合完成\n",
      "\n",
      "成功提取 1860 行\n",
      "✅ IUSQ 聚合完成\n",
      "\n",
      "成功提取 103 行\n",
      "✅ IUSC 聚合完成\n",
      "\n",
      "成功提取 1612 行\n",
      "✅ IQQE 聚合完成\n",
      "\n",
      "成功提取 1113 行\n",
      "✅ EUNM 聚合完成\n",
      "\n",
      "成功提取 417 行\n",
      "✅ IQQY 聚合完成\n",
      "\n",
      "成功提取 433 行\n",
      "✅ EUNK 聚合完成\n",
      "\n",
      "成功提取 341 行\n",
      "✅ IQQU 聚合完成\n",
      "\n",
      "成功提取 188 行\n",
      "✅ IQQJ 聚合完成\n",
      "\n",
      "成功提取 965 行\n",
      "✅ EUNN 聚合完成\n",
      "\n",
      "成功提取 637 行\n",
      "✅ IQQN 聚合完成\n",
      "\n",
      "成功提取 1336 行\n",
      "✅ IQQW 聚合完成\n",
      "\n",
      "成功提取 1392 行\n",
      "✅ EUNL 聚合完成\n",
      "\n",
      "成功提取 1366 行\n",
      "✅ IBCH 聚合完成\n",
      "status code: 403 for ticker EXXT\n",
      "status code: 403 for ticker EXX7\n",
      "status code: 403 for ticker IUSA\n",
      "status code: 403 for ticker IBCF\n",
      "\n",
      "成功提取 88 行\n",
      "✅ IS0E 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 5178, column 195\n",
      "运行出错: not well-formed (invalid token): line 3438, column 195\n",
      "运行出错: not well-formed (invalid token): line 4522, column 194\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "\n",
      "成功提取 613 行\n",
      "✅ EXSA 聚合完成\n",
      "\n",
      "成功提取 64 行\n",
      "✅ EXV1 聚合完成\n",
      "\n",
      "成功提取 147 行\n",
      "✅ ISPA 聚合完成\n",
      "\n",
      "成功提取 1511 行\n",
      "✅ SXRG 聚合完成\n",
      "\n",
      "成功提取 57 行\n",
      "✅ SXRT 聚合完成\n",
      "\n",
      "成功提取 36 行\n",
      "✅ SXRU 聚合完成\n",
      "\n",
      "成功提取 107 行\n",
      "✅ SXRW 聚合完成\n",
      "\n",
      "成功提取 91 行\n",
      "✅ SXR2 聚合完成\n",
      "\n",
      "成功提取 811 行\n",
      "✅ CEBL 聚合完成\n",
      "\n",
      "成功提取 234 行\n",
      "✅ SXR7 聚合完成\n",
      "\n",
      "成功提取 190 行\n",
      "✅ SXR5 聚合完成\n",
      "\n",
      "成功提取 109 行\n",
      "✅ SXR1 聚合完成\n",
      "\n",
      "成功提取 552 行\n",
      "✅ SXR4 聚合完成\n",
      "\n",
      "成功提取 110 行\n",
      "✅ SXRV 聚合完成\n",
      "\n",
      "成功提取 230 行\n",
      "✅ SXRZ 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 42\n",
      "\n",
      "成功提取 3122 行\n",
      "✅ IS3N 聚合完成\n",
      "\n",
      "成功提取 438 行\n",
      "✅ IS3S 聚合完成\n",
      "\n",
      "成功提取 419 行\n",
      "✅ IS3R 聚合完成\n",
      "\n",
      "成功提取 316 行\n",
      "✅ IS3Q 聚合完成\n",
      "\n",
      "成功提取 169 行\n",
      "✅ CEMS 聚合完成\n",
      "\n",
      "成功提取 391 行\n",
      "✅ 36BZ 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "\n",
      "成功提取 158 行\n",
      "✅ QDVR 聚合完成\n",
      "\n",
      "成功提取 247 行\n",
      "✅ QDVS 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 46\n",
      "\n",
      "成功提取 156 行\n",
      "✅ QDVI 聚合完成\n",
      "\n",
      "成功提取 0 行\n",
      "❌ QDVB 聚合失败: 'Gewichtung (%)'\n",
      "\n",
      "成功提取 118 行\n",
      "✅ OM3X 聚合完成\n",
      "\n",
      "成功提取 243 行\n",
      "✅ QDVW 聚合完成\n",
      "\n",
      "成功提取 383 行\n",
      "✅ 2B7K 聚合完成\n",
      "\n",
      "成功提取 383 行\n",
      "✅ 2B7J 聚合完成\n",
      "\n",
      "成功提取 3122 行\n",
      "✅ EIMU 聚合完成\n",
      "\n",
      "成功提取 3479 行\n",
      "✅ IUSN 聚合完成\n",
      "\n",
      "成功提取 170 行\n",
      "✅ NDIA 聚合完成\n",
      "\n",
      "成功提取 131 行\n",
      "✅ LOCK 聚合完成\n",
      "\n",
      "成功提取 54 行\n",
      "✅ 4BRZ 聚合完成\n",
      "\n",
      "成功提取 110 行\n",
      "✅ NQSE 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "\n",
      "成功提取 501 行\n",
      "✅ SGAS 聚合完成\n",
      "\n",
      "成功提取 501 行\n",
      "✅ SLUS 聚合完成\n",
      "\n",
      "成功提取 384 行\n",
      "✅ SLMC 聚合完成\n",
      "\n",
      "成功提取 213 行\n",
      "✅ SLMA 聚合完成\n",
      "\n",
      "成功提取 2728 行\n",
      "✅ OM3Y 聚合完成\n",
      "\n",
      "成功提取 2728 行\n",
      "✅ AYEM 聚合完成\n",
      "\n",
      "成功提取 173 行\n",
      "✅ SGAJ 聚合完成\n",
      "\n",
      "成功提取 1238 行\n",
      "✅ S6DW 聚合完成\n",
      "\n",
      "成功提取 1238 行\n",
      "✅ SNAW 聚合完成\n",
      "\n",
      "成功提取 500 行\n",
      "✅ EDMU 聚合完成\n",
      "\n",
      "成功提取 500 行\n",
      "✅ OM3L 聚合完成\n",
      "\n",
      "成功提取 1144 行\n",
      "✅ EDMW 聚合完成\n",
      "\n",
      "成功提取 1144 行\n",
      "✅ EMND 聚合完成\n",
      "\n",
      "成功提取 385 行\n",
      "✅ EDM6 聚合完成\n",
      "\n",
      "成功提取 385 行\n",
      "✅ EMNU 聚合完成\n",
      "\n",
      "成功提取 180 行\n",
      "✅ EDMJ 聚合完成\n",
      "\n",
      "成功提取 208 行\n",
      "✅ EDM4 聚合完成\n",
      "\n",
      "成功提取 1098 行\n",
      "✅ EDM2 聚合完成\n",
      "\n",
      "成功提取 1098 行\n",
      "✅ EEDM 聚合完成\n",
      "\n",
      "成功提取 568 行\n",
      "✅ ICGA 聚合完成\n",
      "\n",
      "成功提取 156 行\n",
      "✅ AYEW 聚合完成\n",
      "\n",
      "成功提取 1392 行\n",
      "✅ IWLE 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "\n",
      "成功提取 679 行\n",
      "✅ 84X0 聚合完成\n",
      "\n",
      "成功提取 47 行\n",
      "✅ ESIH 聚合完成\n",
      "\n",
      "成功提取 97 行\n",
      "✅ ESIF 聚合完成\n",
      "\n",
      "成功提取 153 行\n",
      "✅ EMPA 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 10392, column 224\n",
      "\n",
      "成功提取 500 行\n",
      "✅ CBUC 聚合完成\n",
      "\n",
      "成功提取 168 行\n",
      "✅ CBUK 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "\n",
      "成功提取 353 行\n",
      "✅ MUSD 聚合完成\n",
      "运行出错: not well-formed (invalid token): line 42, column 52\n",
      "\n",
      "成功提取 417 行\n",
      "✅ CEBZ 聚合完成\n",
      "\n",
      "成功提取 653 行\n",
      "✅ WOEE 聚合完成\n",
      "\n",
      "成功提取 258 行\n",
      "✅ USEE 聚合完成\n",
      "\n",
      "成功提取 187 行\n",
      "✅ N1UD 聚合完成\n",
      "\n",
      "成功提取 821 行\n",
      "✅ IXUA 聚合完成\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "\n",
    "master_industry_list = []\n",
    "master_location_list = []\n",
    "df = []\n",
    "manual_inspect =[]\n",
    "\n",
    "\n",
    "def retrieve_holding_info_from_ishare(download_url, referer_url, ticker):\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": referer_url,  # we are from your own website, plz dont block us :[\n",
    "        \"Accept\": \"text/csv,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    }\n",
    "\n",
    "    # use session to avoid 403 blockage\n",
    "    session = requests.Session()\n",
    "\n",
    "    try:\n",
    "        response = session.get(download_url, headers=headers)\n",
    "        time.sleep(random.randint(1,3))\n",
    "        if response.status_code == 403:\n",
    "            print(f\"status code: {response.status_code} for ticker {ticker}\")\n",
    "            manual_inspect.append(ticker)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(\"holdings_info.xls\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            holdings_df = parse_holdings_xls(\"holdings_info.xls\")\n",
    "            df.append(holdings_df)\n",
    "            try:\n",
    "                ind_df, loc_df = aggregate_etf_data(holdings_df, ticker)\n",
    "\n",
    "                master_industry_list.append(ind_df)\n",
    "                master_location_list.append(loc_df)\n",
    "                print(f\"✅ {ticker} agg successful\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {ticker} agg failed: {e}\")\n",
    "                manual_inspect.append(ticker)\n",
    "\n",
    "            return None\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"somthing's wrong...: {e}\")\n",
    "        manual_inspect.append(ticker)\n",
    "\n",
    "\n",
    "for i in range(len(records_df)):\n",
    "    download_url = records_df['download_url'][i]\n",
    "    referer_url = records_df[\"product_url\"][i]\n",
    "    ticker = records_df[\"ticker\"][i]\n",
    "    retrieve_holding_info_from_ishare(download_url, referer_url, ticker)\n",
    "\n",
    "# agg to industry/location tables\n",
    "final_industry_master = pd.concat(master_industry_list, ignore_index=True)\n",
    "final_location_master = pd.concat(master_location_list, ignore_index=True)\n",
    "final_industry_master[\"Sector\"] = final_industry_master[\"Sector\"].apply(\n",
    "    lambda x: x.strip()\n",
    ")\n",
    "final_location_master[\"Location\"] = final_location_master[\"Location\"].apply(\n",
    "    lambda x: x.strip()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625e5e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manual_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd8d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices=records_df[records_df['ticker'].isin(manual_inspect)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行出错: not well-formed (invalid token): line 42, column 42\n",
      "status code: 403 for ticker IUSC\n",
      "status code: 403 for ticker DAXEX\n",
      "status code: 403 for ticker EXS3\n",
      "\n",
      "成功提取 103 行\n",
      "✅ IUSC 聚合完成\n",
      "status code: 403 for ticker EXXT\n",
      "status code: 403 for ticker EXX7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m referer_url = records_df.loc[idx,\u001b[33m\"\u001b[39m\u001b[33mproduct_url\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m ticker = records_df.loc[idx,\u001b[33m\"\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mretrieve_holding_info_from_ishare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferer_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mretrieve_holding_info_from_ishare\u001b[39m\u001b[34m(download_url, referer_url, ticker)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m     response = session.get(download_url, headers=headers)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstatus code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for ticker \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# try again for those in manual_inspect\n",
    "for idx in selected_indices:\n",
    "    download_url = records_df.loc[idx,'download_url']\n",
    "    referer_url = records_df.loc[idx,\"product_url\"]\n",
    "    ticker = records_df.loc[idx,\"ticker\"]\n",
    "    retrieve_holding_info_from_ishare(download_url, referer_url, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a7882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行出错: not well-formed (invalid token): line 42, column 42\n",
      "status code: 403 for ticker IUSC\n",
      "status code: 403 for ticker DAXEX\n",
      "status code: 403 for ticker EXS3\n",
      "\n",
      "成功提取 103 行\n",
      "✅ IUSC 聚合完成\n",
      "status code: 403 for ticker EXXT\n",
      "status code: 403 for ticker EXX7\n",
      "status code: 403 for ticker IUSA\n",
      "status code: 403 for ticker IBCF\n",
      "运行出错: not well-formed (invalid token): line 5178, column 195\n",
      "运行出错: not well-formed (invalid token): line 3438, column 195\n",
      "运行出错: not well-formed (invalid token): line 4522, column 194\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 42\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 46\n",
      "\n",
      "成功提取 0 行\n",
      "❌ QDVB 聚合失败: 'Gewichtung (%)'\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 10392, column 224\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 37\n",
      "运行出错: not well-formed (invalid token): line 42, column 52\n"
     ]
    }
   ],
   "source": [
    "# for idx in selected_indices:\n",
    "#     download_url = records_df.loc[idx,'download_url']\n",
    "#     referer_url = records_df.loc[idx,\"product_url\"]\n",
    "#     ticker = records_df.loc[idx,\"ticker\"]\n",
    "#     retrieve_holding_info_from_ishare(download_url, referer_url, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f430b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get TER info\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "import re\n",
    "\n",
    "ter_list = []\n",
    "manual_ter_lst = []\n",
    "\n",
    "def get_ter(isin):\n",
    "    url = f\"https://www.justetf.com/en/etf-profile.html?isin={isin}\"\n",
    "\n",
    "    rq = requests.get(url, headers=headers)\n",
    "    if  rq.status_code == 403:\n",
    "        print(isin)\n",
    "    html = rq.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # 找到包含 TER 的 label\n",
    "    labels = soup.find_all(\n",
    "        \"div\",\n",
    "        class_=\"val bold\",\n",
    "        attrs={\"data-testid\": \"etf-profile-header_ter-value\"}\n",
    "    )\n",
    "    ter = None\n",
    "    if len(labels) == 1:\n",
    "        label = labels[0]\n",
    "        ter = label.get_text(strip=True).split()[0]\n",
    "        print(\"ISIN:\",isin,\"TER:\", ter)\n",
    "        pattern = r'(\\d+\\.\\d+)(\\s*%)'\n",
    "        ter= float(re.match(pattern,ter).group(1))\n",
    "        return ({'ISIN':isin,\"TER\":ter})\n",
    "    else:\n",
    "        print(f'ISIN:{isin} not found')\n",
    "        manual_ter_lst.append(isin)\n",
    "        return None\n",
    "        \n",
    "    \n",
    "if not os.path.exists('ter_info.csv'):\n",
    "    for isin in filtered_etf['ISIN'].tolist():\n",
    "        ter_list.append(get_ter(isin))\n",
    "        time.sleep(2)\n",
    "\n",
    "    ter_df = pd.DataFrame(ter_list)\n",
    "    # ter_df.to_csv('ter_info.csv')\n",
    "else:\n",
    "    ter_df = pd.read_csv('ter_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8e34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ter_with_ticker_df = pd.merge(filtered_etf[['Ticker','ISIN']],ter_df,how='right',on='ISIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025fb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_location_master = pd.merge(final_location_master,ter_with_ticker_df,how='left',on='Ticker')\n",
    "# save result\n",
    "final_industry_master.to_csv(\"master_industry_table.csv\", index=False)\n",
    "final_location_master.to_csv(\"master_location_table.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
